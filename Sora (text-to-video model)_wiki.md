### Sora (text-to-video model)


**Sora** is an upcoming [generative artificial intelligence](https://en.wikipedia.org/wiki/Generative_artificial_intelligence) model developed by [OpenAI](https://en.wikipedia.org/wiki/OpenAI), that specializes in [text-to-video](https://en.wikipedia.org/wiki/Text-to-video_model) generation. The model generates short video clips corresponding to [prompts](https://en.wikipedia.org/wiki/Prompt_engineering) from users. Sora can also extend existing short videos. As of July 2024 it is unreleased and not yet available to the public.[[1]](https://en.wikipedia.org/wiki/Sora_(text-to-video_model)#cite_note-NBC-1)

## History[[edit](https://en.wikipedia.org/w/index.php?title=Sora_(text-to-video_model)&action=edit&section=1)]

Several other text-to-video generating models had been created prior to Sora, including [Meta](https://en.wikipedia.org/wiki/Meta_Platforms)'s Make-A-Video, [Runway](https://en.wikipedia.org/wiki/Runway_(company))'s Gen-2, and [Google](https://en.wikipedia.org/wiki/Google)'s Lumiere, the last of which, as of February 2024, is also still in its research phase.[[2]](https://en.wikipedia.org/wiki/Sora_(text-to-video_model)#cite_note-Wired-2) [OpenAI](https://en.wikipedia.org/wiki/OpenAI), the company behind Sora, had released [DALL·E 3](https://en.wikipedia.org/wiki/DALL-E), the third of its DALL-E [text-to-image models](https://en.wikipedia.org/wiki/Text-to-image_model), in September 2023.[[3]](https://en.wikipedia.org/wiki/Sora_(text-to-video_model)#cite_note-CNET-3)

The team that developed Sora named it after [the Japanese word for sky](https://en.wiktionary.org/wiki/%E7%A9%BA#Japanese) to signify its "limitless creative potential".[[4]](https://en.wikipedia.org/wiki/Sora_(text-to-video_model)#cite_note-NYT_CM_2024_02_15-4) On February 15, 2024, OpenAI first previewed Sora by releasing multiple clips of [high-definition videos](https://en.wikipedia.org/wiki/High-definition_video) that it created, including an [SUV](https://en.wikipedia.org/wiki/SUV) driving down a mountain road, an animation of a "short fluffy monster" next to a candle, two people walking through [Tokyo](https://en.wikipedia.org/wiki/Tokyo) in the snow, and fake historical footage of the [California gold rush](https://en.wikipedia.org/wiki/California_gold_rush), and stated that it was able to generate videos up to one minute long.[[2]](https://en.wikipedia.org/wiki/Sora_(text-to-video_model)#cite_note-Wired-2) The company then shared a technical report, which highlighted the methods used to train the model.[[5]](https://en.wikipedia.org/wiki/Sora_(text-to-video_model)#cite_note-OAI_research-5)[[6]](https://en.wikipedia.org/wiki/Sora_(text-to-video_model)#cite_note-ars-6) OpenAI CEO [Sam Altman](https://en.wikipedia.org/wiki/Sam_Altman) also posted a series of tweets, responding to [Twitter](https://en.wikipedia.org/wiki/Twitter) users' prompts with Sora-generated videos of the prompts.

OpenAI has stated that it plans to make Sora available to the public but that it would not be soon; it has not specified when.[[2]](https://en.wikipedia.org/wiki/Sora_(text-to-video_model)#cite_note-Wired-2)[[1]](https://en.wikipedia.org/wiki/Sora_(text-to-video_model)#cite_note-NBC-1) The company provided limited access to a small "[red team](https://en.wikipedia.org/wiki/Red_team)", including experts in misinformation and bias, to perform [adversarial testing](https://en.wikipedia.org/wiki/Adversarial_machine_learning) on the model.[[3]](https://en.wikipedia.org/wiki/Sora_(text-to-video_model)#cite_note-CNET-3) The company also shared Sora with a small group of creative professionals, including video makers and artists, to seek feedback on its usefulness in creative fields.[[7]](https://en.wikipedia.org/wiki/Sora_(text-to-video_model)#cite_note-WDH_MIT_2024_02_15-7)

## Capabilities and limitations[[edit](https://en.wikipedia.org/w/index.php?title=Sora_(text-to-video_model)&action=edit&section=2)]

A video generated by Sora of someone lying in a bed with a cat on it, containing several mistakes

The technology behind Sora is an adaptation of the technology behind [DALL-E 3](https://en.wikipedia.org/wiki/DALL-E_3). According to OpenAI, Sora is a diffusion transformer[[8]](https://en.wikipedia.org/wiki/Sora_(text-to-video_model)#cite_note-8) – a [denoising latent diffusion model](https://en.wikipedia.org/wiki/Diffusion_model) with one [Transformer](https://en.wikipedia.org/wiki/Transformer_(deep_learning_architecture)) as the denoiser. A video is generated in latent space by denoising 3D "patches", then transformed to standard space by a video decompressor. Re-captioning is used to [augment training data](https://en.wikipedia.org/wiki/Data_augmentation), by using a video-to-text model to create detailed captions on videos.[[6]](https://en.wikipedia.org/wiki/Sora_(text-to-video_model)#cite_note-ars-6)

OpenAI trained the model using publicly available videos as well as copyrighted videos licensed for the purpose, but did not reveal the number or the exact source of the videos.[[4]](https://en.wikipedia.org/wiki/Sora_(text-to-video_model)#cite_note-NYT_CM_2024_02_15-4) Upon its release, OpenAI acknowledged some of Sora's shortcomings, including its struggling to simulate complex physics, to understand [causality](https://en.wikipedia.org/wiki/Causality), and to differentiate left from right.[[9]](https://en.wikipedia.org/wiki/Sora_(text-to-video_model)#cite_note-9) One example shows a group of wolf pups seemingly multiplying and converging, creating a hard-to-follow scenario.[[10]](https://en.wikipedia.org/wiki/Sora_(text-to-video_model)#cite_note-10) OpenAI also stated that, in adherence to the company's existing safety practices, Sora will restrict text prompts for sexual, violent, hateful, or celebrity imagery, as well as content featuring pre-existing [intellectual property](https://en.wikipedia.org/wiki/Intellectual_property).[[3]](https://en.wikipedia.org/wiki/Sora_(text-to-video_model)#cite_note-CNET-3)

Tim Brooks, a researcher on Sora, stated that the model figured out how to create [3D graphics](https://en.wikipedia.org/wiki/3D_computer_graphics) from its dataset alone, while Bill Peebles, also a Sora researcher, said that the model automatically created different video angles without being prompted.[[2]](https://en.wikipedia.org/wiki/Sora_(text-to-video_model)#cite_note-Wired-2) According to OpenAI, Sora-generated videos are tagged with [C2PA metadata](https://en.wikipedia.org/wiki/Content_Authenticity_Initiative) to indicate that they were AI-generated.[[4]](https://en.wikipedia.org/wiki/Sora_(text-to-video_model)#cite_note-NYT_CM_2024_02_15-4)

## Reception[[edit](https://en.wikipedia.org/w/index.php?title=Sora_(text-to-video_model)&action=edit&section=3)]

Will Douglas Heaven of the [*MIT Technology Review*](https://en.wikipedia.org/wiki/MIT_Technology_Review) called the demonstration videos "impressive", but noted that they must have been cherry-picked and may not be representative of Sora's typical output.[[7]](https://en.wikipedia.org/wiki/Sora_(text-to-video_model)#cite_note-WDH_MIT_2024_02_15-7) American academic [Oren Etzioni](https://en.wikipedia.org/wiki/Oren_Etzioni) expressed concerns over the technology's ability to create online [disinformation](https://en.wikipedia.org/wiki/Disinformation) for political campaigns.[[4]](https://en.wikipedia.org/wiki/Sora_(text-to-video_model)#cite_note-NYT_CM_2024_02_15-4) For [*Wired*](https://en.wikipedia.org/wiki/Wired_(magazine)), [Steven Levy](https://en.wikipedia.org/wiki/Steven_Levy) similarly wrote that it had the potential to become "a misinformation train wreck" and opined that its preview clips were "impressive" but "not perfect" and that it "show[ed] an emergent grasp of cinematic grammar" due to its unprompted shot changes. Levy added, "[i]t will be a very long time, if ever, before text-to-video threatens actual filmmaking."[[2]](https://en.wikipedia.org/wiki/Sora_(text-to-video_model)#cite_note-Wired-2) Lisa Lacy of [CNET](https://en.wikipedia.org/wiki/CNET) called its example videos "remarkably realistic – except perhaps when a human face appears close up or when sea creatures are swimming".[[3]](https://en.wikipedia.org/wiki/Sora_(text-to-video_model)#cite_note-CNET-3)

Filmmaker [Tyler Perry](https://en.wikipedia.org/wiki/Tyler_Perry) announced he would be putting a planned $800 million expansion of his [Atlanta](https://en.wikipedia.org/wiki/Atlanta) studio on hold, expressing concern about Sora's potential impact on the film industry.[[11]](https://en.wikipedia.org/wiki/Sora_(text-to-video_model)#cite_note-11)[[12]](https://en.wikipedia.org/wiki/Sora_(text-to-video_model)#cite_note-12)

## See also[[edit](https://en.wikipedia.org/w/index.php?title=Sora_(text-to-video_model)&action=edit&section=4)]

- [VideoPoet](https://en.wikipedia.org/wiki/VideoPoet) – Text-to-video model by Google

## References[[edit](https://en.wikipedia.org/w/index.php?title=Sora_(text-to-video_model)&action=edit&section=5)]

1. ^ [Jump up to:***a***](https://en.wikipedia.org/wiki/Sora_(text-to-video_model)#cite_ref-NBC_1-0) [***b***](https://en.wikipedia.org/wiki/Sora_(text-to-video_model)#cite_ref-NBC_1-1) Yang, Angela (February 15, 2024). ["OpenAI teases 'Sora,' its new text-to-video AI model"](https://www.nbcnews.com/tech/tech-news/openai-sora-video-artificial-intelligence-unveiled-rcna139065). [*NBC News*](https://en.wikipedia.org/wiki/NBC_News). [Archived](https://web.archive.org/web/20240215235542/https://www.nbcnews.com/tech/tech-news/openai-sora-video-artificial-intelligence-unveiled-rcna139065) from the original on February 15, 2024. Retrieved February 16, 2024.
2. ^ [Jump up to:***a***](https://en.wikipedia.org/wiki/Sora_(text-to-video_model)#cite_ref-Wired_2-0) [***b***](https://en.wikipedia.org/wiki/Sora_(text-to-video_model)#cite_ref-Wired_2-1) [***c***](https://en.wikipedia.org/wiki/Sora_(text-to-video_model)#cite_ref-Wired_2-2) [***d***](https://en.wikipedia.org/wiki/Sora_(text-to-video_model)#cite_ref-Wired_2-3) [***e***](https://en.wikipedia.org/wiki/Sora_(text-to-video_model)#cite_ref-Wired_2-4) [Levy, Steven](https://en.wikipedia.org/wiki/Steven_Levy) (February 15, 2024). ["OpenAI's Sora Turns AI Prompts Into Photorealistic Videos"](https://www.wired.com/story/openai-sora-generative-ai-video/). [*Wired*](https://en.wikipedia.org/wiki/Wired_(magazine)). [Archived](https://web.archive.org/web/20240215234655/https://www.wired.com/story/openai-sora-generative-ai-video/) from the original on February 15, 2024. Retrieved February 16, 2024.
3. ^ [Jump up to:***a***](https://en.wikipedia.org/wiki/Sora_(text-to-video_model)#cite_ref-CNET_3-0) [***b***](https://en.wikipedia.org/wiki/Sora_(text-to-video_model)#cite_ref-CNET_3-1) [***c***](https://en.wikipedia.org/wiki/Sora_(text-to-video_model)#cite_ref-CNET_3-2) [***d***](https://en.wikipedia.org/wiki/Sora_(text-to-video_model)#cite_ref-CNET_3-3) Lacy, Lisa (February 15, 2024). ["Meet Sora, OpenAI's Text-to-Video Generator"](https://www.cnet.com/tech/meet-sora-openais-text-to-video-generator/). [*CNET*](https://en.wikipedia.org/wiki/CNET). [Archived](https://web.archive.org/web/20240216004932/https://www.cnet.com/tech/meet-sora-openais-text-to-video-generator/) from the original on February 16, 2024. Retrieved February 16, 2024.
4. ^ [Jump up to:***a***](https://en.wikipedia.org/wiki/Sora_(text-to-video_model)#cite_ref-NYT_CM_2024_02_15_4-0) [***b***](https://en.wikipedia.org/wiki/Sora_(text-to-video_model)#cite_ref-NYT_CM_2024_02_15_4-1) [***c***](https://en.wikipedia.org/wiki/Sora_(text-to-video_model)#cite_ref-NYT_CM_2024_02_15_4-2) [***d***](https://en.wikipedia.org/wiki/Sora_(text-to-video_model)#cite_ref-NYT_CM_2024_02_15_4-3) Metz, Cade (February 15, 2024). ["OpenAI Unveils A.I. That Instantly Generates Eye-Popping Videos"](https://www.nytimes.com/2024/02/15/technology/openai-sora-videos.html). [*The New York Times*](https://en.wikipedia.org/wiki/The_New_York_Times). [Archived](https://web.archive.org/web/20240215220626/https://www.nytimes.com/2024/02/15/technology/openai-sora-videos.html) from the original on February 15, 2024. Retrieved February 15, 2024.
5. [**^**](https://en.wikipedia.org/wiki/Sora_(text-to-video_model)#cite_ref-OAI_research_5-0) Brooks, Tim; Peebles, Bill; Holmes, Connor; DePue, Will; Guo, Yufei; Jing, Li; Schnurr, David; Taylor, Joe; Luhman, Troy; Luhman, Eric; Ng, Clarence Wing Yin; Wang, Ricky; Ramesh, Aditya (February 15, 2024). ["Video generation models as world simulators"](https://openai.com/research/video-generation-models-as-world-simulators). [*OpenAI*](https://en.wikipedia.org/wiki/OpenAI). [Archived](https://web.archive.org/web/20240216072133/https://openai.com/research/video-generation-models-as-world-simulators) from the original on February 16, 2024. Retrieved February 16, 2024.
6. ^ [Jump up to:***a***](https://en.wikipedia.org/wiki/Sora_(text-to-video_model)#cite_ref-ars_6-0) [***b***](https://en.wikipedia.org/wiki/Sora_(text-to-video_model)#cite_ref-ars_6-1) Edwards, Benj (February 16, 2024). ["OpenAI collapses media reality with Sora, a photorealistic AI video generator"](https://arstechnica.com/information-technology/2024/02/openai-collapses-media-reality-with-sora-a-photorealistic-ai-video-generator/). [*Ars Technica*](https://en.wikipedia.org/wiki/Ars_Technica). [Archived](https://web.archive.org/web/20240217000922/https://arstechnica.com/information-technology/2024/02/openai-collapses-media-reality-with-sora-a-photorealistic-ai-video-generator/) from the original on February 17, 2024. Retrieved February 17, 2024.
7. ^ [Jump up to:***a***](https://en.wikipedia.org/wiki/Sora_(text-to-video_model)#cite_ref-WDH_MIT_2024_02_15_7-0) [***b***](https://en.wikipedia.org/wiki/Sora_(text-to-video_model)#cite_ref-WDH_MIT_2024_02_15_7-1) Heaven, Will Douglas (February 15, 2024). ["OpenAI teases an amazing new generative video model called Sora"](https://www.technologyreview.com/2024/02/15/1088401/openai-amazing-new-generative-ai-video-model-sora/). [*MIT Technology Review*](https://en.wikipedia.org/wiki/MIT_Technology_Review). [Archived](https://web.archive.org/web/20240215220619/https://www.technologyreview.com/2024/02/15/1088401/openai-amazing-new-generative-ai-video-model-sora/) from the original on February 15, 2024. Retrieved February 15, 2024.
8. [**^**](https://en.wikipedia.org/wiki/Sora_(text-to-video_model)#cite_ref-8) Peebles, William; Xie, Saining (2023). ["Scalable Diffusion Models with Transformers"](https://openaccess.thecvf.com/content/ICCV2023/html/Peebles_Scalable_Diffusion_Models_with_Transformers_ICCV_2023_paper.html). *2023 IEEE/CVF International Conference on Computer Vision (ICCV)*. pp. 4172–4182. [arXiv](https://en.wikipedia.org/wiki/ArXiv_(identifier)):[2212.09748](https://arxiv.org/abs/2212.09748). [doi](https://en.wikipedia.org/wiki/Doi_(identifier)):[10.1109/ICCV51070.2023.00387](https://doi.org/10.1109%2FICCV51070.2023.00387). [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier)) [979-8-3503-0718-4](https://en.wikipedia.org/wiki/Special:BookSources/979-8-3503-0718-4). [ISSN](https://en.wikipedia.org/wiki/ISSN_(identifier)) [2380-7504](https://www.worldcat.org/issn/2380-7504). [S2CID](https://en.wikipedia.org/wiki/S2CID_(identifier)) [254854389](https://api.semanticscholar.org/CorpusID:254854389). [Archived](https://web.archive.org/web/20240217080434/https://openaccess.thecvf.com/content/ICCV2023/html/Peebles_Scalable_Diffusion_Models_with_Transformers_ICCV_2023_paper.html) from the original on February 17, 2024. Retrieved February 17, 2024.
9. [**^**](https://en.wikipedia.org/wiki/Sora_(text-to-video_model)#cite_ref-9) Pequeño IV, Antonio (February 15, 2024). ["OpenAI Reveals 'Sora': AI Video Model Capable Of Realistic Text-To-Video Prompts"](https://www.forbes.com/sites/antoniopequenoiv/2024/02/15/openai-reveals-sora-ai-video-model-capable-of-realistic-text-to-video-prompts/). [*Forbes*](https://en.wikipedia.org/wiki/Forbes). [Archived](https://web.archive.org/web/20240215220634/https://www.forbes.com/sites/antoniopequenoiv/2024/02/15/openai-reveals-sora-ai-video-model-capable-of-realistic-text-to-video-prompts/) from the original on February 15, 2024. Retrieved February 15, 2024.
10. [**^**](https://en.wikipedia.org/wiki/Sora_(text-to-video_model)#cite_ref-10) ["Sora-generated video of wolves playing with some video issues"](https://www.abc.net.au/news/2024-02-16/sora-generated-video-of-wolves-playing-with-some-video-issues-/103476602). *ABC News Australia*. Retrieved May 16, 2024.
11. [**^**](https://en.wikipedia.org/wiki/Sora_(text-to-video_model)#cite_ref-11) Kilkenny, Katie (February 23, 2024). ["Tyler Perry Puts $800M Studio Expansion on Hold After Seeing OpenAI's Sora: "Jobs Are Going to Be Lost""](https://www.hollywoodreporter.com/business/business-news/tyler-perry-ai-alarm-1235833276/). *The Hollywood Reporter*. [Archived](https://web.archive.org/web/20240226021123/https://www.hollywoodreporter.com/business/business-news/tyler-perry-ai-alarm-1235833276/) from the original on February 26, 2024. Retrieved February 26, 2024.
12. [**^**](https://en.wikipedia.org/wiki/Sora_(text-to-video_model)#cite_ref-12) Edwards, Benj (February 23, 2024). ["Tyler Perry puts $800 million studio expansion on hold because of OpenAI's Sora"](https://arstechnica.com/information-technology/2024/02/i-just-dont-see-how-we-survive-tyler-perry-issues-hollywood-warning-over-ai-video-tech/). *Ars Technica*. [Archived](https://web.archive.org/web/20240226021124/https://arstechnica.com/information-technology/2024/02/i-just-dont-see-how-we-survive-tyler-perry-issues-hollywood-warning-over-ai-video-tech/) from the original on February 26, 2024. Retrieved February 26, 2024.